[["index.html", "NRES 341: Intermediate Geomatics for Natural Resource Management Welcome How to use these resources How to get involved", " NRES 341: Intermediate Geomatics for Natural Resource Management Paul D. Pickell 2025-03-10 Welcome These are the course materials for NRES 341 in the Bachelor of Natural Resources program (NRES) at the University of British Columbia (UBC). These Open Educational Resources (OER) were developed to foster the Geomatics Community of Practice that is hosted by the Faculty of Forestry at UBC. These materials are primarily lab assignments that students enrolled in NRES 341 will complete and submit for credit in the program. Note that much of the data referenced are either public datasets or otherwise only available to students enrolled in the course for credit. Deliverables for these assignments are submitted through the UBC learning management system and only students enrolled in the course may submit these assignments for credit. How to use these resources Each “chapter” is a standalone lab assignment designed to be completed over one or two weeks. Students enrolled in NRES 341 will submit all deliverables through the course management system at UBC for credit and should consult the schedule and deadlines posted there. The casual user can still complete the tutorials step-by-step, but the data that are not alreadyh publicly available are not hosted on this website and therefore you will not have access to them. Unless otherwise noted, all materials are Open Educational Resources (OER) and licensed under a Creative Commons license (CC-BY-SA-4.0). Feel free to share and adapt, just be sure to share with the same license and give credit to the author. How to get involved Because this is an open project, we highly encourage contributions from the community. The content is hosted on our GitHub repository and from there you can open an issue or start a discussion. Feel free to open an issue for any typos, factual discrepancies, bugs, or topics you want to see. We are always looking for great Canadian case studies to share! You can also fork our GitHub repository to explore the source code and take the content offline. ## Warning in readLines(file, warn = readLines.warn): incomplete final line found ## on &#39;chapterauthors.yml&#39; "],["landsat-image-processing.html", "Lab 1 Introduction to Landsat Image Processing Lab Overview Task 1: Data Types &amp; Projections Task 2: Cloud and Shadow Masking Task 3: Image Enhancement and Focal Filters", " Lab 1 Introduction to Landsat Image Processing Written by Hana Travers-Smith Lab Overview The Landsat satellite program has been active since 1972 and represents one of the most valuable remote sensing datsets in environmental monitoring and ecology. The Landsat series of satellites measure passive reflectance from the Earth’s surface and atmosphere and is used in the fields of agriculture, forestry, geology and hydrology. In 2008, all Landsat data was made open to the public and this has triggered widespread uptake by governments and research groups across the world. In this lab, you will work with images collected by the Landsat 8 to understand radiometric resolution and get a chance to practice image processing steps including masking clouds and cloud shadows and applying image enhancements. Learning Objectives Understand radiometric resolution and how it relates to Digital Numbers Learn how to resample rasters to common projections Use the Landsat Quality Assurance Band to mask clouds and shadows Understand how image enhancements and focal filters work Deliverables Screenshots of image metadata and histograms Answers to 15 questions posed in the handout Data Two Landsat 8 Surface Reflectance images Task 1: Data Types &amp; Projections You are given two Landsat Surface Reflectance images. LC08_047026_20200830_02_T1_a.tif LC08_047026_20200830_02_T1_b.tif The filenames use the following naming pattern that tells you information about the data product and when the image was acquired: LXSS_PPPRRR_YYYYMMDD_CC_TX.tif L = Landsat X = OLI/TIRS Sensor S = Landsat 8 satellite PPP = WRS path RRR = WRS row YYYYMMDD = Acquistion year, month, day CC = Collection number TX = Collection Category WRS path/row refer to a worldwide grid system, where each Landsat scene is assigned a specific path (longitude) and row (latitude) coordinate. Use the USGS resource to answer the following questions: ‘https://www.usgs.gov/faqs/what-naming-convention-landsat-collections-level-1-scenes’ Q1: For the Landsat scenes you are given, what Landsat sensor and satellite do the images come from? When were the images acquired and what Landsat Collection number are they found in? Q2: Data in Landsat Collections 1 &amp; 2 have been pre-processed so that images across time are geometrically and radiometrically consistent. In 2-4 sentences explain what this means and why it is important for detecting environmental changes. Q3: The following image shows the spectral profile of a vegetated surface before and after atmospheric correction. Describe the differences between the two profiles and explain the properties of the atmosphere that causes this. In your own words, why is it important to correct for atmospheric effects when using satellite imagery collected at different times? Step 1: Import the following rasters LC08_047026_20200830_SR_A.tif and LC08_047026_20200830_SR_B.tif into a new Map Project in ArcGIS Pro. Name the project Lab 1 and save it in the default documents folder on your computer, typically C:\\Users\\YourUsername\\Documents\\ArcGIS\\Projects\\Lab2. The bands are as follows: SR_B2 = Blue SR_B3 = Green SR_B4 = Red SR_B5 = NIR SR_B6 = SWIR1 Experiment with the Symbology tab. Screenshot 1: Upload a screenshot of Raster A in RGB true-color. Screenshot 2: Upload a screenshot of Raster A in false color infrared, with NIR in the red channel. Navigate to &gt; Properties &gt; General and use the image metadata to answer the following questions about the Surface Reflectance rasters. Q4: What are the projections of raster A and raster B? What are the data types? Q5: Define radiometric resolution and describe how it relates to the range of possible values in the image. Q6: How many possible values would be present in an 8-bit, 16-bit and 32-bit image? What are the bit-types of rasters A and B (HINT: look at the min/max values of the rasters)? Zoom in so you can see individual pixels and notice how the different raster projections change how the pixels align. Raster A is in the correct UTM Zone projection, while raster B is not. Q7: Imagine you want to see how the reflectance of a small forest stand changes over time. Why would it be important that your imagery is displayed in the same projection? Step 2: Convert raster B to the NAD 1983 UTM Zone 10 projection using the Project Raster tool and save the result as a new raster. (Analysis &gt; Tools &gt; search for Project Raster) Screenshot 3: Upload a screenshot of the Spatial Reference information (in the General tab) for the new raster. Q8: Which resampling method is most appropriate for continuous data (i.e. temperature, elevation) and why? What about discrete data (i.e. land cover classes, categories)? Task 2: Cloud and Shadow Masking Next, we will use the Quality Assurance (QA) band to mask out pixels covered by clouds and cloud shadows. Landsat (and many other types of remote sensing imagery) use a Bitmask to store information related to the quality of a pixel. For each pixel, a bitmask is a series of classifications for whether the pixel contains clouds, snow, shadows, haze, and other atmospheric artefacts we want to remove. Bitmasks also contain information on the level of confidence in the pixel classification. All this information is stored in an integer that can be transformed into it’s binary counterpart composed of 0’s and 1’s. Using a bitmask reduces the filesize of a raster, as the integer values are shorter than their binary conunterparts. The Landsat QA_BAND is a 15-bit integer, meaning that the pixel values can range from 0 to 2^15. There are 15 different indicators stored in this band that relate to pixel quality (clouds, haze etc…). The full list can be found here (expand the bitmask for QA_PIXEL section): https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_TOA#bands To interpret the pixel value of a bitmask first convert the integer to binary: For example: 22280 becomes 101011100001000 Starting from the right, each value is assigned a Bit Position starting at 0 and counting up to the total number of values. If we want to know if a pixel is cloudy we need to look at bit 3. In this example, bit 3 is represented by the fourth number from the right, and has a value of 1. According to the bitmask, a value of 1 in bit position 3 indicates a pixel with high confidence cloud. You will notice that some of the indicators are represented by multiple bit positions. For example, bits 8-9 encode the degree of confidence in the cloud classification. For our example pixel, bit positions 8-9 contain the values 11, converting this binary number back to integer gives the value 3, which corresponds to High confidence. Use the following online tool to convert between integer and binary numbers and answer the following question: https://www.rapidtables.com/convert/number/binary-to-decimal.html Q9: For a pixel with the integer value 23888, what is the classification for Bit 3: Cloud and Bit 4: Cloud Shadow? What about Bit 10-11: Cloud Shadow Confidence? Step 1: Next, we will create a mask representing pixels we want to keep, then use it to remove cloudy pixels from raster A. First use the Make Raster Layer tool to extract the QA band from the multiband raster. Input raster: LC08_047026_20200830_SR_A.tif Output raster name: QA_band Bands: 6 leave the other settings as defaults. &gt; Run Change the Primary Symbology of the new QA_band so that each integer is assigned a unique color. This will help you see what values represent clear pixels. Your output should look something like the following: Pixels with clear skies are represented by integers 21824 (land) and 21952 (water). Step 2: We will use the Reclassify (Spatial Analyst) tool to create a new raster where clear sky pixels have a value of 1 and all other pixels have a value of 0. Input raster: QA_band Reclass field: VALUE Output raster: Raster_mask Click Unique, for pixel values of 21824 and 21952 set the New value to 1 and 0 for everything else. You should now have a raster that looks like this: To create our mask we will convert this raster to polygon features. Navigate to Analysis &gt; Tools &gt; Raster to Polygon. Input Raster: Raster_mask Field: Value Output Polygon Features: Polygon_mask UNCHECK Simplify polygons (this will ensure polygons will align with the raster cells) Click Run. For the new polygon mask layer, use the Select by Attributes tool to select the polygons corresponding to clouds using the expression: gridcode = 0, then delete these features in the attribute table. Make sure to save your edits. Step 3: We are now ready to mask clouds and shadows from the Landsat scene. Navigate to Analysis &gt; Tools &gt; Extract by Mask Input raster: LC08_047026_20200830_SR_A.tif Input raster or feature mask data: Polygon_mask Output raster: masked_scene Click Run. Screenshot 4: Upload a screenshot of your masked Landsat scene displayed as false color infrared. Make sure you tun off the basemap layer, so the cloud mask is visible. Note that the bands have been renamed 1-6 corresponding to B, G, R, NIR, SWIR, and the QA band. Q10: If you did not have the QA band, what Landsat bands/spectral properties could you use to identify cloudy pixels? Task 3: Image Enhancement and Focal Filters Step 1: View the NIR band of the cloud masked image in greyscale. Symbology &gt; change Primary Symbology to Stretch &gt; Set the band to SR_Band4. Notice which land cover types appear bright, and which appear dark. Q11: What do the light and dark areas of the NIR image represent? How could you use this image to identify vegetation and urban areas? Image enhancement makes it easier to see differences in light/dark areas of an image and aids in visual interpretation. For example, an 8-bit image can contain brightness values that range from 0-255. However, the range of values on a raw image may be smaller (i.e. 50-200), thus this image will have less contrast between the darkest and lightest regions, and will appear more homogeneous. A common image enhancement is called a linear contrast stretch which remaps the values of an image to cover the full dynamic range. Some image enhancements will first remove the highest and lowest values before stretching to get rid of potential outliers. Screenshot 5: Upload a screenshot of the histogram of NIR surface reflectance values. Right-click on the raster layer in the Contents pane &gt; Create Chart &gt; Histogram. Set the variable to the NIR band. Q12: What is a histogram in the context of a remote sensing image? What do the X and Y axes represent? What is the mean value of the cloud masked NIR image? Step 2: Next, we will change the image enhancement in the Symbology tab. Click the histogram symbol. First, change the stretch type to Minimum-Maximum this stretches the image across the full range of values. Next, experiment with moving the sliders along the bottom of the histogram, this will change the minimum and maximum values displayed in the image, and the linear stretch will be applied across this new range. Notice how the image on the map changes. The grey bars in the background show the original distribution of the values, and the red bars show the stretched values. You can see that applying this transformation increases the range of brightness values across the image. See the following link for more information about the strech types available in ArcPro: https://pro.arcgis.com/en/pro-app/latest/help/data/imagery/raster-display-ribbon.htm Q13: Describe how applying a linear stretch changes the appearance of the imagery. What happens as you decrease the maximum value? Next, we will explore how focal filters work and apply a Sharpening and Smoothing filter. Focal filters change the pixel values in an image by considering the values of the surrounding pixels. First, a focal window is defined around a target pixel. In a raster image this is usually the 8 adjacent pixels that touch the target pixel (forming a 3x3 grid). The values of the target pixel and pixels in the focal window are used to calculate a new value for the target pixel. In the example below, the focal filter assigns the target pixel (green) the value of the maximum value in the focal window (blue). The window then moves across the image, and every pixel in the image is transformed to a new value. Another common filter calculates the mean value of the pixels in the window: Q14: Use the following matrix to calculate the target pixel value (green) using a 3x3 mean filter. More advanced filters use weighted functions, where the pixels in the window are multiplied by a weighting factor that makes them more or less influential in calculating the target value. Shapening and Smoothing filters use weighted means to enhance or smooth the edges of features in an image. For more information see: https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/convolution-function.htm Step 3: Apply a 3x3 Sharpening and Smoothing filter to the cloud masked image using the Convolution Tool in the Raster Functions menu. Screenshot 6: Upload a screenshot of the sharpened image. Screenshot 7: Upload a screeenshot of the smoothed image. Q15: Describe how the sharpened and smoothed images differ in terms of the variation in pixel values. Give an example of how each filter might enhance the image interpretation. ## Warning in readLines(file, warn = readLines.warn): incomplete final line found ## on &#39;chapterauthors.yml&#39; "],["landsat-image-classification.html", "Lab 2 Landsat Image Classification in ArcGIS Pro Lab Overview Learning Objectives Deliverables Data Task 1: Prepare data for analysis Task 2: Unsupervised Image Classification Task 3: Supervised Image Classification", " Lab 2 Landsat Image Classification in ArcGIS Pro Written by Paul Pickell Lab Overview Image classification is a common task in image analysis. Land cover classification maps can be useful for calculating the total area of different classes and other spatial information about a land base. In this lab, we will explore simple methods that involve thresholding a spectral index and more complex unsupervised and supervised algorithms. At the end, you will be asked to reflect on the choices and assumptions that were made and what impact those have on the final classification and how we can use it. Learning Objectives Calculate a simple spectral index Apply supervised and unsupervised classification algorithms to create a land cover map Interpet a confusion matrix Deliverables Answers to questions posed throughout the lab handout Screenshot of NDVI image Screenshot of ISO cluster map Screenshot of confusion matrix Map of supervised EOSD land cover classification Data We will be using a Landsat 9 Operational Land Imager 2 (OLI-2) multispectral image and other metadata that are distributed with this product. You can download these data from Canvas. Task 1: Prepare data for analysis Step 1: Open ArcGIS Pro and create a new project. Download the lab data from Canvas and extract those data into your ArcGIS Pro project folder that you just created, usually in C:\\Users\\you\\Documents\\ArcGIS\\Projects\\lab2. Step 2: Search for the “Compsite Bands” tool in ArcGIS Pro. Add all of the seven surface reflectance bands and then name the output “sr_composite.tif” and save it in your ArcGIS Pro project folder. Step 3: Right-click the sr_composite.tif layer and open the symbology. Create a 6-5-4 false colour image. Next, we will calculate some spectral indices from this composite image. Spectral indices are mathematical equations containing spectral reflectance values from two or more wavelengths used to highlight areas of spectral importance in an image. There are a wide variety of spectral indices used to highlight a variety of different land covers and image properties. The Normalized Difference Vegetation Index (NDVI) is a frequently used spectral index that takes advantage of the high near-infrared reflectance and high red absorption properties of healthy vegetation and is therefore often used to quantify vegetation in a remotely sensed multispectral image. NDVI is calculated with the below formula: \\(\\ NDVI = \\frac{(NIR - RED)}{(NIR+RED)}\\) Where NIR is the near-infrared band (Landsat 9 Band 5) and Red is the red band (Landsat 9 Band 4). The results of this equation should be an index with values ranging between -1 and 1. Values less than 0 represent water (i.e., a higher absorption of NIR compared to Red) and values between 0-1 representing different levels of green vegetation. ArcGIS Pro contains several ways to calculate common indices like NDVI. In this lab we will be using the “band arithmetic” function as it is a bit more flexible and easier to understand. Step 4: Navigate to the Imagery tab on the ribbon at the top of your ArcGIS Pro window and click the “Raster Function” button. The Raster Functions pane should appear, you can either navigate the drop down menus to “Math” &gt; “Band Arithmetic” or use the search function to find the “Band Arithmetic Tool” and click to open. The “Band Arithmetic Properties” dialogue should appear. Under “Raster” use the drop down menu and select the sr_composite.tif layer. If it is not currently in your map view and can use the folder button and navigate to your lab data folder and select the file. Under “Method” select “User Defined”. Using your knowledge of spectral indices, fill in the NDVI calculation for your data. Screenshot 1: Upload a screenshot of your NDVI image. Q1. What are the minimum and maximum values of your new NDVI layer? Q2. What do the dark areas in the image represent? The gray areas? The white? Q3. What information does this type of analysis give us? When and why might this type of analysis be used? Next, we will use a technique called thresholding to extract highly vegetated areas (high NDVI). Step 5: Under the “Analysis” ribbon select the “Tools” option. The geoprocessing window should appear in the search box type “Reclassify” and select the option with “(Spatial Analyst Tools)” beside it. Step 6: Select the NDVI band arithmetic raster layer that you produced from Task 1. Reclassify the NDVI values so that values greater than or equal to 0.3 have a new value of 1 and all others have a value of NODATA. Under “Output Raster” save the file as “ndvi_threshold.tif” and run the tool. Task 2: Unsupervised Image Classification Step 1: Left-click on the sr_composite.tif layer in your Contents pane to select it. Step 2: From the top ribbon, select “Imagery”, then click the “Classification Tools” button and finally select “Classify”. Step 3: At the top of the tool, select “ISO Cluster” from the “Classifer drop-down menu. Set”Maximum Number of Classes” to 10. Change the “Output Classified Dataset” name to “iso_cluster.tif” and run the tool. Step 4: Inspect the output. You may want to open the layer Symbology and change the color scheme to a random set of colours. From the Symbology pane, you can change the “Label” of each class value to anything your want by double-clicking the cell and typing any text. Spend some time interpreting the unsupervised classes and providing appropriate labels for each. You may want to toggle between the ISO cluster classification and the 6-5-4 false colour image to aid your interpretations. Screenshot 2: Upload a screenshot of your ISO cluster map result with your labelled legend visible in the Contents pane. Task 3: Supervised Image Classification Step 1: Left-click on the sr_composite.tif layer in your Contents pane to select it. Step 2: From the top ribbon, select “Imagery”, then click the “Classification Tools” button and finally select “Training Samples Manager”. In the tool, you should see the “NLCD2011” classification scheme pre-loaded at the top and it contains some generic classes. If you do not, you can load it by clicking the folder icon and then selecting “Use default schema”. NLCD stands for National Land Cover Database and 2011 is the nominal year that this schema was produced for. “National” in this case refers to the United States, not Canada. This is a land cover schema you would typically find for the United States. Canada has a similar land cover dataset called Earth Observation for Sustainable Development of Forests (EOSD). We are going to create a new schema that uses the Canadian labels from the EOSD legend. Step 3: Click the button to the left of the folder icon to “Create New Schema”. This will get rid of the NLCD2011 schema that was loaded and allow you to start populating the class values. To add a new class value, click the green plus mark + and then type the name of the class and then the value of that class to be encoded in the raster. If you want, you can pick colours for your classes at this stage or just accept the default. Using this process, enter the classes in the following table as your new schema: Class Name Value Water 20 Snow/Ice 31 Rock/Rubble 32 Exposed/Barren Land 33 Shrubs 50 Wetland 80 Wetland-Treed 81 Herbs 100 Coniferous Forest 210 Broadleaf 220 Mixedwood 230 Your final schema should look like the image below. You might want to save your schema now in case you need to stop the lab and finish later. Step 4: Left-click on any class in the schema in order to make the digitizing tools available at the top. Once a class is selected, you can choose to digitize a training sample for that class using a rectangle, polygon, circle or free-hand by selecting one of those tools at the top. Then, you can digitize directly onto the map. You will want to have the 6-5-4 false colour image displayed and you will want to digitize training samples that are relatively small and homogenous, so be careful with how you draw your lines. Repeat this process until you have about 5-8 training samples per class. This will take a great deal of interpretation and you may not be able to distinguish between “Wetland” and “Wetland-Treed”, but do your best. If you cannot find any samples for a class, skip it. Feel free to consult other information to help you create the training samples. When you are finished creating training samples, save them into your project geodatabase as “EOSD_training_samples”. Step 5: Left-click on the sr_composite.tif layer in the Contents pane and then from the ribbon select “Imagery”, “Classification Tools”, and “Classify”. Change the “Classifier” to “Maximum Likelihood” and navigate to the “EOSD_training_samples” that you saved in your geodatabase for the Training Samples. Save the “Output Classified Dataset” as “EOSD_Classified”, then run the tool. Before we can actually place testing points on our map, we need to change the EOSD classification raster by replacing 0 with NoData/Null. Zero is a valid value to ArcGIS Pro, but it is not an actual class, so setting these zeros to NoData/Null ensures that we will not sample in those areas. Step 6: From the Geoprocessing pane, search for the “Set Null” tool (Image Analyst). Add the CA_forest_VLCE2_2022_clip.tif as the Input Conditional Raster (this is the classified EOSD land cover). Change the expression so that it reads “WHERE VALUE is equal to 0”, this is the conditional statement that we are going to test. If the tool finds any values of 0 in the raster (grey coloured in the screenshot above), then those will be set to NoData/Null. Under “Input false raster or constant value”, you will select CA_forest_VLCE2_2022_clip.tif again. This is because if the value is not 0 (false), then we want to keep the existing value in the EOSD classification. Name the output CA_forest_VLCE2_2022_clip_null.tif (or CA_forest_VLCE2_2022_clip_null if you save it inside your geodatabase) and then run the tool. Step 7: From the Geoprocessing pane, search for the “Create Accuracy Assessment Points” tool. Add the CA_forest_VLCE2_2022_clip_null.tif (or CA_forest_VLCE2_2022_clip_null if you saved inside your geodatabase) as the Input Raster (this is the classified EOSD land cover). Save the Output Accuracy Assessment Points as “eosd_accuracy_assessment_points” in your project geodatabase. Change the Target Filed to “Ground Truth”, leave the other parameters as default and then run the tool. This will generate 500 points randomly stratified across the classes in the official EOSD land cover classification. Open the attribute table to inspect the output. Step 8: From the Geoprocessing pane, search for the “Update Accuracy Assessment Points” tool. This time, we are going to select our “EOSD_Classified” image that we classified earlier as the Input Raster. The Input and Output Accuracy Assessment Points can be the same points that you created in the last step. Change the “Target Field” to “Classified”, leave “Dimension Field for Test points” blank, and then run the tool. Step 9: From the Geoprocessing pane, search for the “Compute Confusion Matrix” tool. Use the “eosd_accuracy_assessment_points” as the Input Accuracy Assessment Points and save the output as “confusion_matrix” in your geodatabase then run the tool. Screenshot 3: Upload a screenshot of your confusion matrix. Q4. Which of your classes had the highest User’s accuracy? Why? Q5. Which of your classes had the lowest User’s accuracy? Why? Q6. Which of your classes had the highest Producer’s accuracy? Why? Q7. Which of your classes had the lowest Producer’s accuracy? Why? Q8. Compare and contrast your unsupervised classification with your supervised classification. How did these methods compare with the very simple thresholding approach you did earlier with NDVI? Q9. How did the thematic resolution of the EOSD classification impact your ability to discern classes in an urban environment? If you had to do this again, are there any classes that you would drop, combine, or introduce? Export a professional map of your final supervised EOSD classification and upload to Canvas. ## Warning in readLines(file, warn = readLines.warn): incomplete final line found ## on &#39;chapterauthors.yml&#39; "],["lidar-forest-management.html", "Lab 3 LiDAR Point Clouds for Forest Management Lab Overview Task 1: Load and understand LiDAR data in a Map Project Task 2: Create a DEM, DSM and CHM Task 3: Mapping Tree Tops Task 4: Visualization in 3D", " Lab 3 LiDAR Point Clouds for Forest Management Written by Hana Travers-Smith Lab Overview LiDAR, short for Light Detection and Ranging, is a remote sensing technology that uses laser pulses to measure distances and create detailed 3D maps of objects and environments. To map vegetation, LiDAR emits laser beams from an aircraft or ground-based system towards the vegetation canopy. The laser pulses bounce back upon hitting objects, including leaves, branches, and the ground. By measuring the time it takes for the pulses to return, LiDAR calculates the distance to each point, generating a “point cloud” of data. “Point clouds” can be used to create high-resolution maps depicting the vertical structure of vegetation, including tree heights, density, and ground cover. These maps are invaluable for understanding ecosystem health, biodiversity, carbon storage, and assisting in land management decisions such as forest monitoring, conservation planning, and urban development. In this lab you will use high resolution LiDAR data collected by the City of Vancouver to create a model of terrain and vegetation for a forest located on UBC campus. Learning Objectives Understand how LiDAR data is collected Learn how to model terrain and vegetation from a LiDAR point cloud Visualize 3D data in a Scene Deliverables Screenshots of CHM and final 3D scene Answers to 11 questions posed in the lab Data Lidar data collected by the City of Vancouver in .las format Task 1: Load and understand LiDAR data in a Map Project Step 1: Download the LiDAR data from the following link: https://opendata.vancouver.ca/explore/dataset/lidar-2018/information/ THe data is split up into a tiled grid system. You will download one tile covering a section of UBC. Use the Table view and search for the following tile and download it: 4840E_54550N by clicking on the .zip link. Use the metadata from the City of Vancouver data portal to answer the following questions: Q1. What is the horizontal and vertical datum of the LAS dataset? Why is it important for Lidar data to have both horiziantal AND vertical datums? Q2: What is the point density of the dataset (points per m2)? Step 2: Create a new ArcGIS Map Project name it Lab5 and save it to the default directory. ArcGIS Pro has several tools that we can use to view and analyse LiDAR point clouds. In order to view the dataset, we need to import it as a LAS Dataset. Analysis &gt; Tools &gt; type ‘Create LAS dataset’ in the search box. Input File: 4840E_54550N.las Output LAS Dataset: LAS Dataset.lasd Coodinate System: Use the horizontal datum from the dataset specifications Create PRJ for LAS Files: All LAS files Check the ‘Compute Statistics’ box. Surface Constraints can be left blank Step 3: Depending on the zoom extent, you may only see the red bounding box of the las file; this isn’t an error, you just need to zoom in to see the actual points. The points can be classified into the following categories: Ground Non-Ground 1st Return (highest feature) The default display is that no point cloud filters are applied. To quickly filter only ground points right click on the file in the Contents Pane, navigate to ‘LAS Filters’, and click ‘Ground’. There is also a more detailed classification system, which includes vegetation, water, noise, buildings etc. Right-click on the the file &gt; Properties &gt; LAS Filter. This menu gives you more control for which points you want to display from the dataset. Task 2: Create a DEM, DSM and CHM In this task we will create 3 raster datasets by interpolating heights from the point cloud to create continuous surfaces: Digitial Elevation Model (DEM) - sometimes referred to as a Digitial Terrain Model (DTM) Digital Surface Model (DSM) Canopy Height Model (CHM) Q3: What does a DEM, DSM and CHM represent? How do you interpret the values in each one? Step 1: First, we will create a DEM from the .lasd point cloud. Filter the point cloud so that only points labelled ‘02 Ground’ are displayed. Analysis &gt; Tools &gt; Search for LAS Dataset to Raster. We will use the Binning method to interpolate elevation. This method works by dividing the point cloud into cells (pixels) and assigning a value to each cell based on the heights of all the points in the cell. For example, cell values could be assigned as the average height of all points within a 10x10m pixel. Input LAS Dataset: LAS Dataset.lasd Output Raster: DEM Value Field: Elevation Interpolation Type: Binning Cell Assignment: Average Void Fill Method: Linear Output Data Type: Floating Point Sampling Type: Cell size Sampling Value: 10 (this defines the resolution of the output raster as 10m) Z factor: 1 Q4: What is the minimum and maximum value of the DEM? You should now have something that looks like this: Step 2: Next, we will create a DSM. We need to ensure that all point labelled as ‘Noise’ are filtered out from the dataset, we will also filter out ‘Ground’ points and just retain points coming from vegetation/infrastructure. Navigate to the LAS Filter menu in the data Properties tab. Uncheck the following codes: 0 Never Classified 1 Unassigned 2 Ground 7 Noise Once you have correctly filtered the point cloud open the LAS Dataset to Raster tool. This time we will use the Maximum value as the Cell Assignment. Name the output raster DSM. All other settings can stay the same as the DEM. &gt; Run Q5: Why might we want to use the Maximum value as the Cell Assignment method for a DSM? Q6: What features or land cover types can you idenify from the DSM? Step 3: Finally, we will create a CHM using the DEM and DSM. Navigate to Analysis &gt; Tools &gt; Raster Calculator (Image Analyst Tools).This tool allows you to create a new raster by combining multiple rasters using simple mathematical operators (adding, subtracting etc). Calculate the CHM as: DSM - DEM Q7: Explain why we need to subtract the DEM from the DSM to calculate canopy height. Describe potential sources of error in deriving a CHM from this method. Screenshot 1: Upload a screenshot of your final CHM. Change the default symbology to show unvegetated areas, medium vegetation &lt;30m and tall vegetation &gt;30m. Task 3: Mapping Tree Tops Using what you learned in the last task, now you will create a point shapefile of treetops using a higher resolution canopy height model. Step 1: First, we will derive a DSM using points representing High Vegetation. Open the LAS Filter menu and make sure only points labelled 5 High Vegetation are checked. Next, use the LAS Dataset to Raster tool to create a raster from the filtered point cloud with the following properties: 1m spatial resolution the raster values should represent the highest point in each cell name the output DSM_1m Step 2: Next, produce a DEM DEM_1m at the same spatial resolution of 1m using what you learned in the last task. Step 3: Again following what you learned in the last task, subtract the 1m DEM from the 1m DSM and name the output file TreeTops. Q8: What features are now visible in the 1m DSM that were not visible in the 10m DSM? Step 4: Next we will use the Focal Statistics Tool to identify the maximum height of tree crowns across the forest. We will use a Circular Neighborhood with a Radius of 5. This will calculate the maximum elevation observed within a 11m circular moving window (5m is the radius, 10m is the diameter, plus one more cell for the focal cell = 11m). Use the following parameters: Input raster: TreeTops Output raster: TreeTop_max Neighbourhood: Circle Radius: 5 Unit type: Cell Statistic Type: Maximum Ignore no data in calculations: Checked Q9: What is a moving window? If you are using a focal maximum, explain how cell values assigned in the final output. Step 3: Open the Raster Calculator tool. We will use this tool to find the pixels in the TreeTops raster that match the maximum focal height in the TreeTops_max. To do this, we will use a True/False conditional statement using the Con syntax: Con(statement, iftrue, if false) - Essentially for each pixel the statement is evaulated and if it is true an action is taken, and if it is false a different action is taken. Enter the following statement in the Raster Calculator tool: Con(“TreeTops”==”TreeTops_max”, ”TreeTops_max”) Basically, this is a calculation that evaluates the statement “where is the TreeTops raster equal to the maximum elevation value identified from the focal statistics?” Where these pixels match, write the maximum value to the output. Otherwise, write a value of NoData to the output. Save the output as tree_with_height. Refer to the screenshot below for writing this statement correctly. Inspect the output. Zooming in reveals what we have done. Pixels that represent the maximum height in each focal window are assigned a value equal to the maximum height, while all other pixels have a NoData value. Step 4: Open the ‘Raster to Point’ tool. The input raster is the raster that you just made. Field is Value, and the output name should be ‘tree_with_height’. Input: tree_with_height Field: Value Output: Final_treetops Q10: How many tree tops are in the final output? Task 4: Visualization in 3D So far we have worked with the point cloud data in flat, 2-dimensional space. In this task, you will explore the point cloud in 3-dimensions in a Scene. On the top ribbon Insert &gt; New Map &gt; New Local Scene. Step 1: Practice using the On Screen Navigator to manipulate the scene. The first toggle let’s you navigate in the normal directions and the second toggle (the person) let’s you rotate the scene in 3D. Step 2: Navigate to the UBC campus study area and change the Basemap to Imagery in the Map tab located on the top ribbon. In the Contents pane, right-click Ground, located below the Elevation Surfaces group layer. Click ‘Add Elevation Source’. Browse to the location of your 10m DSM and select it. You can now start to see how the surface features have been incorporated into the surface. Make sure to zoom in to look at areas with high relief and roads. Add the TreeTops_Final point shapefile to the Scene. Step 3: Click on ‘Ground’ underneath the Elevation Surfaces tab. On the top ribbon click ’Elevation Surface Layer. Set the Vertical Exaggeration to 2 - this will increase the contrast between high/low elevation in the scene. Finally, turn off the WOrldElevation3D/Terrain3d layer to better see how the DSM. Screenshot 2: Upload a screenshot of the final Scene. Add the tree tops points to the visualization. (See example below, note that yours will also include the tree tops points). Q11: Experiment with the 10m and 1m DSM. How does the DSM resolution impact the 3D visualization? Which visualization is more realistic? ## Warning in readLines(file, warn = readLines.warn): incomplete final line found ## on &#39;chapterauthors.yml&#39; "],["terrain-hydrology-analysis.html", "Lab 4 Terrain and Hydology Analysis Lab Overview Task 1: Understanding DEMs Task 2: Identifying Stream Networks Task 3: Mapping Watersheds", " Lab 4 Terrain and Hydology Analysis Written by Hana Travers-Smith Lab Overview A Digital Elevation Model (DEM) is a digital representation of the Earth’s terrain including mountains, valleys, rivers, and other topographic features. They are typically created using remote sensing technology, such as radar or LiDAR (Light Detection and Ranging), which capture elevation data points across the landscape. Typically, these elevation data points are organized into raster format, where each raster cell represents elevation within specific pixel. DEMs are used in a range of applications, including cartography, hydrology, geology, environmental analysis, and simulating water flow and erosion. In this lab you will use a DEM and the Hydrology toolset in ArcGIS Pro to map stream networks and watersheds within critical salmon spawning habitat in Nahmint, BC. Learning Objectives Understand how data is represented in a DEM Learn how to derive slope, aspect and Topographic Position Index (TPI) using raster focal calculations Use the Hydrology Toolbox to map stream networks and watershed boundaries Deliverables Answers to 10 questions in the handout A map of the Nahmint watersheds and stream networks Data DEM of the Nahmint watershed region, BC Task 1: Understanding DEMs Step 1: Create a new ArcGIS Project name it Lab4 and save it to the default directory. Import the Nahmint_DTM.tif and examine the Source information (right-click on the layer in the Catalog pane). Q1: What is the Projected Coordinate System and spatial resolution of the data? Q2: What is the Pixel Type and Pixel Depth? How many possible values can be represented by this data? (Report answer as an exponent.) Q3: What is the difference between a signed and unsigned integer? Which would represent elevation best and why? Step 2: First, we will use the Fill tool to remove any sinks from the DEM. Sinks are small imperfections in the DEM that create areas where water cannot flow out of. The image below shows the side profile of sink and how its gets filled by the Fill tool. If sinks are not eliminated, water flow can get trapped within these depressions, leading to unrealistic pooling of water and incorrect delineation of watershed boundaries. Navigate to Analysis &gt; Tools &gt; Fill (Spatial Analyst). Input Surface Raster: Nahmint_DTM.tiff Output Surface Raster: Nahmint_fill Z limit: leave blank Save the output to the default file path (in your ArcMap project). The Z-limit represents the minimum depth of sinks that will be filled. For example, if it is set to 10m then only sinks deeper than 10m will be filled. For now leave this field blank, this will fill all sinks in the data. Q4: Why might you want to set a specific z-value? Task 2: Identifying Stream Networks Step 1: Next we will use the Flow Direction tool to to calculate the direction of water flow across the landscape. There are three flow modelling algorithms, but we will use the simplest: D8. In this model water will flow from one cell its steepest downslope neighbour. The cell will then be assigned a value based on which of its 8 neightbours water will flow into. Q5: The following raster shows elevation above sea level. What is the flow direction from the centre cell? Report your answer in terms of cardinal direction (North, South, Northwest etc) Use the ArcGis help page to answer to following question: https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/flow-direction.htm Q6: If a cell is assigned a Flow Direction value of 32, what cardinal direction is water flowing out of the cell? Navigate to Tools &gt; Search Flow Direction Input surface raster: Nahmint_fill Output flow direction raster: Nahmint_FlowDir Flow Direction Type: D8 Leave the rest blank/unchecked Click Run. You should now have something like the following: Q7: For the areas marked A and B, approximately what direction is water flowing? Step 2: We will use the flow direction raster calculated in the last step to calculate flow accumulation, which counts the total number of cells that will flow into each cell. For example, a cell located at the bottom of the hill will have high flow accumulation and a cell at the top of a hill will not have any flow accumulation. Navigate to Analysis &gt; Tools &gt; Flow Accumulation Input flow direction raster: Nahmint_FlowDir Output flow accumulation raster: FlowAcc Output data type: Integer Input flow direction type: D8 Leave all other fields blank. &gt; Run. Step 4: Next, we will create a raster based stream network using a threshold in the flow accumulation raster. For example, if the threshold is 100, then only cells with flow accumulation greater than 100 will be counted as a stream. Cells with flow accumulation less than 100 will be set to a background value of 0. To see how different thresholds impact stream identification, change the Symbology of the flow accumulation raster and use the Manual Interval symbology to set two classes. See the example below for a stream network with a flow accumulation threshold of 100 (cells with flow accumulation &lt; 100 are set to no color). Q8: How does the stream network change if you change the threshold from 10, 1000 or 3000? Include a screenshot of each stream network using the different thresholds. Q9: Compare your stream network to the streams visible in the ArcGIS sastellite basemaps. Experiment with different flow acculuation thresholds. Which one seems to represent major streams in the satellite basemaps best? What other land cover/infastructure in this region may make it difficult to verify smaller stream netowrks? Once you have selected a threshold, navigate to the Reclassify (Spatial Analyst Tools) tool. Use the threshold you have selected as the start and end values. Set the cells representing streams to a new value of 1 and all other cells to NO DATA. Save the new raster as StreamNetwork Step 5: Finally, we will use the Stream to Feature (Spatial Analyst Tools) tool to create polyline features representing our stream network. THis tool uses the stream network and the flow direction layers. See this ArcGIS help page for more information: https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/stream-to-feature.htm Navigate to Analysis &gt; Tools &gt; Stream to Feature Input stream raster: StreamNetwork Input flow direction raster: Nahmint_FlowDir Output polyline features: StreamNetwork_lines Simplify polylines: Checked Task 3: Mapping Watersheds A watershed is an area of land where all the water that falls or flows into it converges to a common outlet, such as a river, lake, or ocean. It is bounded by a topographic or drainage divide, which separates water flowing into different basins. In this task we will delineate the boundaries of the Nahmint watershed. The watershed tool uses flow direction and stream links to delineate watershed boundaries. Stream links represent the individual stream segments that make up the entire network. The watershed boundaries will be defined such that water flows into each of the stream links. Step 1: First, we will use the Stream Link tool to generate the links. Use the raster stream network and the flow direction raster as the inputs. Save the new raster as StreamLinks &gt; Run. Step 2: Navigate to Analysis &gt; Tools &gt; Watershed Input D8 flow direction raster: Nahmint_FlowDir Input raster or feature pour point data: StreamLinks Output raster: Nahmint_watersheds The output will be a new raster where the cell values correspond to each unique watershed catchment. Q10: How many unique watersheds did you define? What is the area of the largest watershed area? Report your answer in km2 and round to 2 decimal places. HINT: Examine the raster attribute table to estiamte watershed area. Step 4: Create a map and include it in the final deliverables. The map must have the following elements: Stream network polylines Watershed polygons - assign different colors to each polygon Title North arrow Scale bar Legend ## Warning in readLines(file, warn = readLines.warn): incomplete final line found ## on &#39;chapterauthors.yml&#39; "],["sea-level-rise-suitability.html", "Lab 5 Mapping suitability and sea level rise Lab Overview Task 1: Mapping flood hazard Task 2: Intersection Task 3: Calculating &amp; visualizing suitability", " Lab 5 Mapping suitability and sea level rise Written by Hana Travers-Smith Lab Overview Climate change is rapidly altering the stability of the Earth’s cryosphere. Over the next century thawing glaciers and ice sheets are expected to result in sea level rise between 2-5 m. This is a concern for many coastal environments and communities. In this lab you will use a digital elevation model (DEM) covering the metro Vancouver region to map areas at risk of flooding during an extreme weather event under current and future conditions, assuming 2.96 m of sea level rise by the year 2100. In particular, we will focus on mapping the intersection of high risk areas with critical agricultural land in the Fraser Delta region. In this assignment, you will produce a map to assess regions where agricultural land can be developed safely from flood hazards. In partnership with the Delta community, the Collaborative for Advanced Landscape Planning (CALP) research group at UBC produced the following report on projected sea level rise and adaptation strategies for this region, which can be found here: Delta-RAC Sea Level Rise Adaptation Visioning Study (54.4 MB) Learning Objectives Understand how to use basic spatial analysis tools (Clip, Intersect, Buffer) Experiment with visualization of spatial layers Conduct a suitability analysis to determine where to expand new agricultural land Deliverables Answers to 13 questions Map showing suitability of agricultural areas for future development Data Digital Elevation Model of the Fraser Valley: FraserValleyDEM.tif Polygon of study area: fraserValley_studyarea.shp Polyline of coastline: coastline.shp Polygon shapefile of agricultural land from https://catalogue.data.gov.bc.ca/dataset/alc-alr-polygons: ag_polys.shp Task 1: Mapping flood hazard Peak water levels during a storm are expected to reach 2.96m above current sea level by 2100 (CALP, 2012). In this lab, we will assess flooding in the delta region to inform future land use planning. For now, we will map flood hazard assuming sea walls and dyke infrastructure is not in place, and there are no obstructions blocking the flow of water over the land. Q1: From the CALP report (Section 2), briefly list the 4 primary drivers of sea level rise? Step 1: Set up a new Map Project and import the DEM into ArcGIS Pro. First we will identify cells in the DEM that are below the projected high water line of 2.96m. Open the FraserValleyDEM.tif in ArcGIS Pro. Navigate to Analysis &gt; Tools &gt; Reclassify (Spatial Analyst tools). Click the Classify button and in the pop-up window set the number of classes to 2 and the method to Manual Interval. Set the Upper value to 2.96 and hit OK. In the Output raster field give the new raster a descriptive name (ie DEM_reclass_2m) and save it to the default GDB. HINT: Giving concise and descriptive names to your spatial data will make things easier to keep track of later on! Note that names should not include periods or spaces Cells in the resulting raster with a value &lt;2.96 will be assigned a new value of 1 and cells &gt;2.96 will be assigned a value of 2. Q2. What is the spatial resolution of the DEM? Step 2: Next, we will convert the reclassified raster into polygon features. Navigate to the Raster to Polygon Tool (Conversion Tools). Set the input raster to the reclassified raster (DEM_reclass_2m) from the previous step and name the features flood_2m_polys and save to the default GDB. Make sure the Simplify Polygons box is checked. Q3: What would happen if we did not simplify the polygon features? Why might we want to produce simplified polygon features? Step 3: Open the attribute table for the polygon features. The Gridcode variable corresponds to the cell values from the input raster. In this case we are only interested in keeping polygons representing low elevation cells. We will delete high elevation polygons by selecting features with gridcode = 2 Click Select by Attributes and use the drop-down menus to generate the following expression: Where, gridcode, is equal to, 2 Click the Delete Selection button to delete the selected polygons. Step 4: Examine the resulting polygon shapefile. You will notice that there are lots of small isolated polygons, not adjacent to the coastline. We will remove these by intersecting the flooded areas features with a polyline representing the coastline. Open Coastline.shp. Navigate to Map &gt; Select by Location. Set the Input Features to the flooded areas polygons and the Selecting Features to the coastline layer. Set the Relationship to Within a distance. Set the distance to 30m. Make sure the Invert spatial relationship box is checked. This will select polygons that are further than 30m from the coast. Click Apply. Delete the selected features. Q4: Describe how you would change the selection parameters (Relationship &amp; Distance) if you wanted to select flooded areas that are within 100m from the coastline? You should now have polygon features that look like the following: Step 5: Zoom into the polygons. You will notice that even though we used simplified polygons, the edges are still quite jagged and have many small holes. Next, we will smooth these polygons for better visualization and create more realistic shapes. First, we will reduce the jagged edges in the polygons. Navigate to the Buffer tool. Create a 30m buffer around the flood_2m_polys layer. Set the Dissolve type to Disolve all output features to a single feature. Name the output flood_2m_30mBuffer Click Run. Q5: Describe what happens if the buffer is NOT dissolved. Which would be better (dissolved or not dissolved) if you wanted to calculate the total flooded area in km2 and why? Next, we will clip the flooded polygons to land area using the FraserValley_studyarea.shp. Import FraserValley_studyarea.shp. Navigate to the Clip tool and set the Input features to the flood_2m_30mBuffer layer and the Clip features to the FraserValley.shp. Save the output as flood_2m_30mBuffer_Clip. Click Run. Task 2: Intersection In this task we will intersect flooded areas with with land suitable for agricultural development to understand how sea level rise might impact future land use planning. Q6: The figure below illustrates how the intersect tool works. Describe in one sentence how the output features are generated from the inputs. Step 1:Load the flooded_2m_30mBuffer_Clip layer in ArcPro. Load the agricultural land shapefile, ag_polys.shp. Step 2: Open the Intersect tool. Input Features: flooded_2m_30mBuffer_Clip and ag_polys Attributes to Join: All attributes except feature IDs Output Name: flood_ag_intersect Open the attribute table of the new intersect output, and the layers you used as inputs. Notice how the attributes of both the original input layers are retained in the new intersected features. Q7: What layer did the STATUS and AREA_SQM attributes originally come from? Step 3: Next, we will calculate the flooded area within each agricultural polygon. First, create a new attribute in flood_ag_intersect. Open the layer attribute table and click the Add button beside Field: In the Fields table name the new field FloodedArea, set the data type to Double and then click Save (at the top of map window). You will now have a blank field in the attribute table. In the attribute table, right click on the Int_Area field &gt; Calculate Geometry. In the Property drop-down select Area and select Square meters as the Area Unit. Click OK. Q8: What is the total area of agricultural land is impacted by flooding? Report the final answer in km2 and round to two decimal places. Q9: For the feature with LRPLD = 5118996, what percentage of the polygon is flooded? Round to two decimal places. Task 3: Calculating &amp; visualizing suitability In this task, we will calculate NON-flooded area in each agricultural polygon to determine which regions may be most suitable to develop new agricultural land. Step 1: Create a new attribute in flood_ag_intersect, set it to type = Double and name it SuitableArea. Open the attribute table and open the Calculate Field tool (beside the Add Field tool). Use the fields list and the math symbols to calculate SuitableArea as Area of the agriculture polygon - flooded area. Q10: What is the LRPLD number of the polygon feature with the MOST suitable land for future agriculture? What percentage of the total area is suitable? Step 2: Create another new attribute ProportionFlooded and use Calculate Field to calculate the proportion of each agricultural polygon that is flooded. Your final values should range between 0 and 1. Make sure the data type for the attribute is Double so it can store decimal values. Q11: What expression did you use to calculate ProportionFlooded? (Copy it from the Calculate Field tool). Step 3: Next, we will standardize the SuitableArea attribute so its values range from 0 to 1 (the same range as the ProportionFlooded. Create a new attribute SuitArea_Std and use the following equation to calculate it: SuitArea_Std = (SuitableArea - Minimum) / (Maximum - Minimum) Where Minimum is the minimum value of SuitableArea, and Maximum is the Maximum value of suitableArea. Step 4: Next, we will create a Suitability Score that combines the ProportionFlooded attribute and the SuitArea_Std attribute. Create a new attribute to represent a final Suitability Score and set the Data Type to Double. Use the equation below to create a Suitability Score based on the proportion of non-flooded land and the total suitable area (standardized). The final values will range from 0 (least suitable) to 1 (most suitable): ((1-ProportionFlooded) + SuitArea_Std)/2 Q12: What is the average suitability score? Step 5: Next, we will join the new attribures from the flood_ag_intersect layer to the original ag_polys shapefile so that we can visualize the Suitability Score within the agricultural polygons. Right click on the ag_polys layer in the Contents pane &gt; Joins and Relates &gt; Add Join. Join Features: flood_ag_intersect Join Attribute: LRPLD Un-check Keep all target features Step 6 Change the Symbology of the ag_polys layer to reflect the Suitability Score. Finally, create a map with the following elements and include it in your final deliverables: Agricultural polygons color coded by suitability score Title North arrow Scale bar Legend Q13: Based on your analysis where is the best areas to safely expand agricultural land? What other land use types may compete for this land? "]]
